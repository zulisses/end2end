nohup: ignorando entrada

train_dir=/home/ucarvalho/DDSM-all/patchesS5Nhs/train
val_dir=/home/ucarvalho/DDSM-all/patchesS5Nhs/val
test_dir=/home/ucarvalho/DDSM-all/patchesS5Nhs/test

>>> Model training options: <<<
 {'img_size': [224, 224], 'img_scale': 224.0, 'rescale_factor': None, 'featurewise_center': True, 'featurewise_mean': 59.6, 'equalize_hist': True, 'batch_size': 32, 'train_bs_multiplier': 1.0, 'augmentation': True, 'class_list': ['background', 'malignant', 'benign'], 'nb_epoch': 3, 'top_layer_epochs': 13, 'all_layer_epochs': 50, 'load_val_ram': False, 'load_train_ram': False, 'net': 'vgg16', 'nb_init_filter': 64, 'init_filter_size': 7, 'init_conv_stride': 2, 'pool_size': 3, 'pool_stride': 2, 'weight_decay': 0.01, 'weight_decay2': 0.0001, 'alpha': 0.0001, 'l1_ratio': 0.5, 'inp_dropout': 0.5, 'hidden_dropout': 0.0, 'hidden_dropout2': 0.0, 'optim': 'adam', 'init_lr': 0.001, 'lr_patience': 2, 'es_patience': 18, 'resume_from': None, 'auto_batch_balance': True, 'pos_cls_weight': 1.0, 'neg_cls_weight': 1.0, 'use_pretrained': True, 'top_layer_nb': 15, 'top_layer_multiplier': 0.1, 'all_layer_multiplier': 0.01, 'best_model': '/home/ucarvalho/DDSM-all/best_model.h5', 'final_model': '/home/ucarvalho/DDSM-all/finalmodel.h5'} 

12
1
Loading vgg16,
Using TensorFlow backend.
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/dicom/__init__.py:53: UserWarning: 
This code is using an older version of pydicom, which is no longer 
maintained as of Jan 2017.  You can access the new pydicom features and API 
by installing `pydicom` from PyPI.
See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org 
for more information.

  warnings.warn(msg)
WARNING:tensorflow:From /home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2024-11-11 12:05:20.178068: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2024-11-11 12:05:20.178238: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:From /home/ucarvalho/miniconda3/envs/amb1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Done.
Create generator for train set
Found 19317 images belonging to 3 classes.
Create generator for val set
Found 6822 images belonging to 3 classes.
Start model training
on the last dense layer only
Epoch 1/3
Epoch 00000: val_acc improved from -inf to 0.35387, saving model to /home/ucarvalho/DDSM-all/best_model.h5
14401s - loss: 3.8684 - acc: 0.4972 - val_loss: 1.3987 - val_acc: 0.3539
Epoch 2/3
Epoch 00001: val_acc improved from 0.35387 to 0.40830, saving model to /home/ucarvalho/DDSM-all/best_model.h5
14427s - loss: 3.6046 - acc: 0.5127 - val_loss: 1.3428 - val_acc: 0.4083
Epoch 3/3
Epoch 00002: val_acc did not improve
14437s - loss: 3.6502 - acc: 0.5044 - val_loss: 1.5514 - val_acc: 0.3894
Done.
top layer nb = 15
Start training on the top layers only
Epoch 4/13
Epoch 00003: val_acc did not improve
16099s - loss: 2.4571 - acc: 0.6970 - val_loss: 1.8227 - val_acc: 0.3776
Epoch 5/13
Epoch 00004: val_acc improved from 0.40830 to 0.73504, saving model to /home/ucarvalho/DDSM-all/best_model.h5
16058s - loss: 2.7057 - acc: 0.6144 - val_loss: 1.0806 - val_acc: 0.7350
Epoch 6/13
Epoch 00005: val_acc did not improve
16302s - loss: 2.6367 - acc: 0.5953 - val_loss: 1.0311 - val_acc: 0.7055
Epoch 7/13
Epoch 00006: val_acc did not improve
16311s - loss: 2.5977 - acc: 0.6163 - val_loss: 1.3559 - val_acc: 0.3411
Epoch 8/13
Epoch 00007: val_acc improved from 0.73504 to 0.86488, saving model to /home/ucarvalho/DDSM-all/best_model.h5
16074s - loss: 2.6383 - acc: 0.5793 - val_loss: 0.8004 - val_acc: 0.8649
Epoch 9/13
Epoch 00008: val_acc did not improve
16284s - loss: 2.6965 - acc: 0.5808 - val_loss: 1.3164 - val_acc: 0.5556
Epoch 10/13
Epoch 00009: val_acc did not improve
15973s - loss: 2.7989 - acc: 0.5179 - val_loss: 1.0525 - val_acc: 0.3483
Epoch 11/13
Epoch 00010: val_acc did not improve
16078s - loss: 2.8676 - acc: 0.6003 - val_loss: 1.0025 - val_acc: 0.8242
Epoch 12/13
Epoch 00011: val_acc did not improve
16197s - loss: 2.8297 - acc: 0.5963 - val_loss: 1.6465 - val_acc: 0.6678
Epoch 13/13
Epoch 00012: val_acc improved from 0.86488 to 0.89891, saving model to /home/ucarvalho/DDSM-all/best_model.h5
16801s - loss: 2.9820 - acc: 0.5702 - val_loss: 0.9639 - val_acc: 0.8989
Done.
Start training on all layers
Epoch 14/50
Epoch 00013: val_acc did not improve
36291s - loss: 3.3146 - acc: 0.5650 - val_loss: 1.2516 - val_acc: 0.8398
Epoch 15/50
Epoch 00014: val_acc improved from 0.89891 to 0.98680, saving model to /home/ucarvalho/DDSM-all/best_model.h5
36431s - loss: 2.7982 - acc: 0.5991 - val_loss: 0.9559 - val_acc: 0.9868
Epoch 16/50
Epoch 00015: val_acc did not improve
35896s - loss: 2.6112 - acc: 0.6182 - val_loss: 1.3911 - val_acc: 0.6068
Epoch 17/50
Epoch 00016: val_acc did not improve
35949s - loss: 2.5136 - acc: 0.6329 - val_loss: 0.9921 - val_acc: 0.8190
Epoch 18/50
Epoch 00017: val_acc did not improve
35886s - loss: 2.5715 - acc: 0.6423 - val_loss: 0.8288 - val_acc: 0.8369
Epoch 19/50
Epoch 00018: val_acc did not improve
35968s - loss: 2.4570 - acc: 0.6656 - val_loss: 1.8525 - val_acc: 0.5430
Epoch 20/50
Epoch 00019: val_acc did not improve
35854s - loss: 2.5721 - acc: 0.6589 - val_loss: 1.3734 - val_acc: 0.6034
Epoch 21/50
Epoch 00020: val_acc did not improve
35951s - loss: 2.4446 - acc: 0.6730 - val_loss: 0.7900 - val_acc: 0.8787
Epoch 22/50
Epoch 00021: val_acc did not improve
35988s - loss: 2.4441 - acc: 0.6605 - val_loss: 1.2301 - val_acc: 0.6602
Epoch 23/50
Epoch 00022: val_acc did not improve
35836s - loss: 2.4992 - acc: 0.6576 - val_loss: 0.8582 - val_acc: 0.7947
Epoch 24/50
Epoch 00023: val_acc did not improve
35967s - loss: 2.5219 - acc: 0.6510 - val_loss: 1.2179 - val_acc: 0.6736
Epoch 25/50
Epoch 00024: val_acc did not improve
35668s - loss: 2.4865 - acc: 0.6403 - val_loss: 1.1774 - val_acc: 0.6153
Epoch 26/50
Epoch 00025: val_acc did not improve
35920s - loss: 2.3501 - acc: 0.6833 - val_loss: 1.1141 - val_acc: 0.6964
Epoch 27/50
Epoch 00026: val_acc did not improve
35940s - loss: 2.2564 - acc: 0.6985 - val_loss: 1.2236 - val_acc: 0.6165
Epoch 28/50
Epoch 00027: val_acc did not improve
35900s - loss: 2.3421 - acc: 0.6817 - val_loss: 1.5043 - val_acc: 0.6401
Epoch 29/50
Epoch 00028: val_acc did not improve
35803s - loss: 2.2863 - acc: 0.6970 - val_loss: 0.9601 - val_acc: 0.7607
Epoch 30/50
Epoch 00029: val_acc did not improve
35823s - loss: 2.3118 - acc: 0.6896 - val_loss: 0.9803 - val_acc: 0.7227
Epoch 31/50
Epoch 00030: val_acc did not improve
35970s - loss: 2.3660 - acc: 0.6849 - val_loss: 1.0700 - val_acc: 0.6496
Epoch 32/50
Epoch 00031: val_acc did not improve
35975s - loss: 2.3560 - acc: 0.6886 - val_loss: 0.9756 - val_acc: 0.7204
Epoch 33/50
Epoch 00032: val_acc did not improve
35954s - loss: 2.1548 - acc: 0.7093 - val_loss: 0.7838 - val_acc: 0.8206
Epoch 34/50
Epoch 00033: val_acc did not improve
35890s - loss: 2.3848 - acc: 0.6778 - val_loss: 0.9904 - val_acc: 0.7315
Epoch 35/50
Epoch 00034: val_acc did not improve
35825s - loss: 2.1922 - acc: 0.7060 - val_loss: 1.0466 - val_acc: 0.7061
Epoch 36/50
Epoch 00035: val_acc did not improve
35951s - loss: 2.3741 - acc: 0.6773 - val_loss: 0.7345 - val_acc: 0.8264
Epoch 37/50
Epoch 00036: val_acc did not improve
35675s - loss: 2.2741 - acc: 0.6819 - val_loss: 0.5269 - val_acc: 0.8634
Epoch 38/50
Epoch 00037: val_acc did not improve
35840s - loss: 2.2001 - acc: 0.7068 - val_loss: 0.9041 - val_acc: 0.7158
Epoch 39/50
Epoch 00038: val_acc did not improve
35965s - loss: 2.1966 - acc: 0.6957 - val_loss: 0.8421 - val_acc: 0.6758
Epoch 40/50
Epoch 00039: val_acc did not improve
35923s - loss: 2.1766 - acc: 0.6917 - val_loss: 0.7502 - val_acc: 0.7328
Epoch 41/50
Epoch 00040: val_acc did not improve
35816s - loss: 2.3763 - acc: 0.6916 - val_loss: 1.5847 - val_acc: 0.5502
Epoch 42/50
Epoch 00041: val_acc did not improve
35905s - loss: 2.0499 - acc: 0.7312 - val_loss: 0.9012 - val_acc: 0.9017
Epoch 43/50
Epoch 00042: val_acc did not improve
35925s - loss: 2.2500 - acc: 0.6761 - val_loss: 0.7976 - val_acc: 0.7133
Epoch 44/50
Epoch 00043: val_acc did not improve
35795s - loss: 2.2473 - acc: 0.7065 - val_loss: 0.5844 - val_acc: 0.8360
Epoch 45/50
Epoch 00044: val_acc did not improve
35812s - loss: 2.1443 - acc: 0.7274 - val_loss: 1.0517 - val_acc: 0.7020
Epoch 46/50
Epoch 00045: val_acc did not improve
36803s - loss: 2.2055 - acc: 0.7081 - val_loss: 0.7526 - val_acc: 0.7796
Epoch 47/50
Epoch 00046: val_acc did not improve
35917s - loss: 2.1504 - acc: 0.7036 - val_loss: 0.7452 - val_acc: 0.7820
Epoch 48/50
Epoch 00047: val_acc did not improve
35870s - loss: 2.0812 - acc: 0.7353 - val_loss: 0.7991 - val_acc: 0.7612
Epoch 49/50
Epoch 00048: val_acc did not improve
35737s - loss: 2.3114 - acc: 0.6829 - val_loss: 0.5993 - val_acc: 0.8622
Epoch 50/50
Epoch 00049: val_acc did not improve
35902s - loss: 2.1943 - acc: 0.7192 - val_loss: 1.2129 - val_acc: 0.6401
Done.

==== Training summary ====
Minimum val loss achieved at epoch: 37
Best val loss: 0.526886051809284
Best val accuracy: 0.8634096244131455

==== Predicting on test set ====
Found 6534 images belonging to 3 classes.
Test samples = 6534
Load saved best model: /home/ucarvalho/DDSM-all/best_model.h5. None
Done.
Evaluation result on test set: [0.9502959771483552, 0.9954044117647058]
