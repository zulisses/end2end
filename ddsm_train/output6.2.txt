
train_dir=/home/ulisses/DDSM-all/patchesbkg/train_out
val_dir=/home/ulisses/DDSM-all/patchesbkg/val_out_under
test_dir=/home/ulisses/DDSM-all/patchesbkg/test_out_under

>>> Model training options: <<<
 {'img_size': [224, 224], 'img_scale': 224.0, 'rescale_factor': None, 'featurewise_center': True, 'featurewise_mean': 59.6, 'equalize_hist': True, 'batch_size': 32, 'train_bs_multiplier': 1.0, 'augmentation': True, 'class_list': ['background', 'malignant', 'benign'], 'nb_epoch': 3, 'top_layer_epochs': 13, 'all_layer_epochs': 50, 'load_val_ram': False, 'load_train_ram': False, 'net': 'vgg16', 'nb_init_filter': 64, 'init_filter_size': 7, 'init_conv_stride': 2, 'pool_size': 3, 'pool_stride': 2, 'weight_decay': 0.01, 'weight_decay2': 0.0001, 'alpha': 0.0001, 'l1_ratio': 0.5, 'inp_dropout': 0.5, 'hidden_dropout': 0.4, 'hidden_dropout2': 0.4, 'optim': 'adam', 'init_lr': 0.001, 'lr_patience': 2, 'es_patience': 18, 'resume_from': None, 'auto_batch_balance': True, 'pos_cls_weight': 1.0, 'neg_cls_weight': 1.0, 'use_pretrained': True, 'top_layer_nb': 15, 'top_layer_multiplier': 0.1, 'all_layer_multiplier': 0.01, 'best_model': '/home/ulisses/DDSM-all/best_model.h5', 'final_model': '/home/ulisses/DDSM-all/finalmodel.h5'} 

12
1
Loading vgg16,
Using TensorFlow backend.
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/dicom/__init__.py:53: UserWarning: 
This code is using an older version of pydicom, which is no longer 
maintained as of Jan 2017.  You can access the new pydicom features and API 
by installing `pydicom` from PyPI.
See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org 
for more information.

  warnings.warn(msg)
WARNING:tensorflow:From /home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2024-09-22 22:48:28.486629: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2024-09-22 22:48:28.486755: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:From /home/ulisses/miniconda3/envs/amb1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Done.
Create generator for train set
Found 4680 images belonging to 3 classes.
Create generator for val set
Found 414 images belonging to 3 classes.
Start model training
on the last dense layer only
Epoch 1/3
Epoch 00000: val_acc improved from -inf to 0.40625, saving model to /home/ulisses/DDSM-all/best_model.h5
1394s - loss: 7.7022 - acc: 0.3793 - val_loss: 1.4103 - val_acc: 0.4062
Epoch 2/3
Epoch 00001: val_acc did not improve
1388s - loss: 4.9920 - acc: 0.4409 - val_loss: 1.5398 - val_acc: 0.2995
Epoch 3/3
Epoch 00002: val_acc did not improve
1389s - loss: 4.1231 - acc: 0.4592 - val_loss: 1.1702 - val_acc: 0.3646
Done.
top layer nb = 15
Start training on the top layers only
Epoch 4/13
Epoch 00003: val_acc improved from 0.40625 to 0.70052, saving model to /home/ulisses/DDSM-all/best_model.h5
1608s - loss: 2.1605 - acc: 0.7260 - val_loss: 1.0215 - val_acc: 0.7005
Epoch 5/13
Epoch 00004: val_acc did not improve
1605s - loss: 2.3545 - acc: 0.6575 - val_loss: 0.9633 - val_acc: 0.5885
Epoch 6/13
Epoch 00005: val_acc improved from 0.70052 to 0.80469, saving model to /home/ulisses/DDSM-all/best_model.h5
1599s - loss: 2.4722 - acc: 0.6437 - val_loss: 0.7781 - val_acc: 0.8047
Epoch 7/13
Epoch 00006: val_acc did not improve
1602s - loss: 2.7367 - acc: 0.6016 - val_loss: 1.0053 - val_acc: 0.4349
Epoch 8/13
Epoch 00007: val_acc improved from 0.80469 to 0.93750, saving model to /home/ulisses/DDSM-all/best_model.h5
1595s - loss: 3.0787 - acc: 0.5332 - val_loss: 0.8103 - val_acc: 0.9375
Epoch 9/13
Epoch 00008: val_acc did not improve
1596s - loss: 2.9685 - acc: 0.5330 - val_loss: 1.0810 - val_acc: 0.6458
Epoch 10/13
Epoch 00009: val_acc did not improve
1595s - loss: 2.5404 - acc: 0.5969 - val_loss: 0.6451 - val_acc: 0.7240
Epoch 11/13
Epoch 00010: val_acc did not improve
1590s - loss: 2.6374 - acc: 0.6148 - val_loss: 1.2089 - val_acc: 0.5781
Epoch 12/13
Epoch 00011: val_acc did not improve
1593s - loss: 2.7690 - acc: 0.5510 - val_loss: 1.4819 - val_acc: 0.7266
Epoch 13/13
Epoch 00012: val_acc did not improve
1588s - loss: 2.9703 - acc: 0.5387 - val_loss: 0.8810 - val_acc: 0.6823
Done.
Start training on all layers
Epoch 14/50
Epoch 00013: val_acc did not improve
4227s - loss: 2.5885 - acc: 0.5925 - val_loss: 1.0218 - val_acc: 0.7969
Epoch 15/50
Epoch 00014: val_acc did not improve
4222s - loss: 2.3346 - acc: 0.6307 - val_loss: 1.1659 - val_acc: 0.6146
Epoch 16/50
Epoch 00015: val_acc did not improve
4217s - loss: 2.2269 - acc: 0.6767 - val_loss: 1.1261 - val_acc: 0.6146
Epoch 17/50
Epoch 00016: val_acc did not improve
4234s - loss: 2.3763 - acc: 0.6448 - val_loss: 0.9560 - val_acc: 0.6406
Epoch 18/50
Epoch 00017: val_acc did not improve
4254s - loss: 2.2217 - acc: 0.6777 - val_loss: 1.2231 - val_acc: 0.7031
Epoch 19/50
Epoch 00018: val_acc did not improve
4264s - loss: 2.4886 - acc: 0.6369 - val_loss: 1.2845 - val_acc: 0.6250
Epoch 20/50
Epoch 00019: val_acc did not improve
4296s - loss: 2.2101 - acc: 0.6775 - val_loss: 1.0433 - val_acc: 0.7917
Epoch 21/50
Epoch 00020: val_acc did not improve
4319s - loss: 2.0440 - acc: 0.7304 - val_loss: 1.1295 - val_acc: 0.7083
Epoch 22/50
Epoch 00021: val_acc did not improve
4340s - loss: 1.8637 - acc: 0.7088 - val_loss: 1.3228 - val_acc: 0.6406
Epoch 23/50
Epoch 00022: val_acc did not improve
4346s - loss: 2.1590 - acc: 0.6930 - val_loss: 1.2230 - val_acc: 0.7448
Epoch 24/50
Epoch 00023: val_acc did not improve
4343s - loss: 2.0938 - acc: 0.7151 - val_loss: 2.3045 - val_acc: 0.4167
Epoch 25/50
Epoch 00024: val_acc did not improve
4091s - loss: 2.2880 - acc: 0.6845 - val_loss: 3.6804 - val_acc: 0.3594
Epoch 26/50
Epoch 00025: val_acc did not improve
4278s - loss: 2.2923 - acc: 0.6664 - val_loss: 1.2931 - val_acc: 0.5885
Epoch 27/50
Epoch 00026: val_acc did not improve
4274s - loss: 2.2179 - acc: 0.6588 - val_loss: 1.6060 - val_acc: 0.6094
Epoch 28/50
Epoch 00027: val_acc did not improve
4263s - loss: 2.3771 - acc: 0.6490 - val_loss: 0.8260 - val_acc: 0.7240
Epoch 29/50
Epoch 00028: val_acc improved from 0.93750 to 0.95312, saving model to /home/ulisses/DDSM-all/best_model.h5
4291s - loss: 1.8382 - acc: 0.7207 - val_loss: 0.3895 - val_acc: 0.9531
Epoch 30/50
Epoch 00029: val_acc did not improve
4285s - loss: 2.2233 - acc: 0.6924 - val_loss: 0.8235 - val_acc: 0.8073
Epoch 31/50
Epoch 00030: val_acc did not improve
4277s - loss: 2.1832 - acc: 0.6971 - val_loss: 0.5552 - val_acc: 0.9115
Epoch 32/50
Epoch 00031: val_acc did not improve
4277s - loss: 2.0816 - acc: 0.6918 - val_loss: 0.5588 - val_acc: 0.9219
Epoch 33/50
Epoch 00032: val_acc did not improve
4272s - loss: 2.0529 - acc: 0.7226 - val_loss: 0.9548 - val_acc: 0.7760
Epoch 34/50
Epoch 00033: val_acc did not improve
4260s - loss: 2.0255 - acc: 0.7079 - val_loss: 1.0581 - val_acc: 0.7396
Epoch 35/50
Epoch 00034: val_acc did not improve
4254s - loss: 2.0284 - acc: 0.7375 - val_loss: 0.7316 - val_acc: 0.8854
Epoch 36/50
Epoch 00035: val_acc did not improve
4227s - loss: 2.1523 - acc: 0.6892 - val_loss: 0.9746 - val_acc: 0.6823
Epoch 37/50
Epoch 00036: val_acc improved from 0.95312 to 0.95833, saving model to /home/ulisses/DDSM-all/best_model.h5
4005s - loss: 1.9626 - acc: 0.7261 - val_loss: 0.4494 - val_acc: 0.9583
Epoch 38/50
Epoch 00037: val_acc did not improve
4241s - loss: 2.3370 - acc: 0.6828 - val_loss: 0.7645 - val_acc: 0.8281
Epoch 39/50
Epoch 00038: val_acc did not improve
4286s - loss: 2.1063 - acc: 0.7417 - val_loss: 0.9159 - val_acc: 0.7917
Epoch 40/50
Epoch 00039: val_acc did not improve
4290s - loss: 1.9172 - acc: 0.7632 - val_loss: 0.9736 - val_acc: 0.7969
Epoch 41/50
Epoch 00040: val_acc did not improve
4302s - loss: 2.0535 - acc: 0.7109 - val_loss: 0.9477 - val_acc: 0.7917
Epoch 42/50
Epoch 00041: val_acc did not improve
4324s - loss: 2.0574 - acc: 0.7083 - val_loss: 0.6376 - val_acc: 0.9167
Epoch 43/50
Epoch 00042: val_acc did not improve
4332s - loss: 1.8746 - acc: 0.7302 - val_loss: 0.8098 - val_acc: 0.6510
Epoch 44/50
Epoch 00043: val_acc did not improve
4338s - loss: 1.6810 - acc: 0.7753 - val_loss: 0.8131 - val_acc: 0.8229
Epoch 45/50
Epoch 00044: val_acc did not improve
4324s - loss: 1.9310 - acc: 0.7358 - val_loss: 0.5982 - val_acc: 0.8594
Epoch 46/50
Epoch 00045: val_acc did not improve
4299s - loss: 1.9978 - acc: 0.7364 - val_loss: 0.6806 - val_acc: 0.8385
Epoch 47/50
Epoch 00046: val_acc did not improve
4273s - loss: 1.9519 - acc: 0.7232 - val_loss: 0.6407 - val_acc: 0.9010
Epoch 48/50
Epoch 00047: val_acc did not improve
4271s - loss: 2.2189 - acc: 0.7415 - val_loss: 0.4060 - val_acc: 0.8958
Epoch 00047: early stopping
Done.

==== Training summary ====
Minimum val loss achieved at epoch: 29
Best val loss: 0.3894863078991572
Best val accuracy: 0.953125

==== Predicting on test set ====
Found 801 images belonging to 3 classes.
Test samples = 801
Load saved best model: /home/ulisses/DDSM-all/best_model.h5. None
Done.
Evaluation result on test set: [0.48521028757095336, 0.935]
